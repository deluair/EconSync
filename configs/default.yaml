# EconSync Default Configuration

# Project Information
project_name: "EconSync"
version: "0.1.0"
debug: false
seed: 42

# LoRA Configuration
lora:
  rank: 16
  alpha: 32
  dropout: 0.1
  target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
  bias: "none"
  task_type: "CAUSAL_LM"

# RAG Configuration
rag:
  vector_db_type: "chroma"
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  chunk_size: 512
  chunk_overlap: 50
  top_k: 5
  similarity_threshold: 0.7
  collection_name: "econsync_knowledge"

# ReAct Configuration
react:
  max_iterations: 10
  reasoning_model: "gpt-3.5-turbo"
  temperature: 0.7
  max_tokens: 1000
  action_timeout: 30

# Model Configuration
model:
  base_model: "microsoft/DialoGPT-medium"
  tokenizer: "microsoft/DialoGPT-medium"
  device: "auto"
  torch_dtype: "float16"
  load_in_4bit: true
  load_in_8bit: false

# Data Configuration
data:
  data_dir: "data"
  cache_dir: ".cache"
  max_sequence_length: 2048
  batch_size: 16
  num_workers: 4
  pin_memory: true 