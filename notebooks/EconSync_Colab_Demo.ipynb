{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üåç EconSync: Smart Agent for Applied Economics Research\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deluair/EconSync/blob/main/notebooks/EconSync_Colab_Demo.ipynb)\n",
        "\n",
        "This notebook demonstrates the EconSync system - an AI agent integrating LoRA, RAG, and ReAct frameworks for economics research.\n",
        "\n",
        "## üí∞ Cost-Optimized Configuration\n",
        "- Uses lightweight models suitable for Colab free tier\n",
        "- Synthetic data generation instead of expensive APIs\n",
        "- Simplified LoRA adapters\n",
        "- Local vector database (ChromaDB)\n",
        "\n",
        "**Estimated Costs:**\n",
        "- Colab Free: $0/month (limited GPU hours)\n",
        "- Colab Pro: $9.99/month (more GPU/RAM)\n",
        "- Colab Pro+: $49.99/month (premium resources)\n",
        "\n",
        "**Production Costs (AWS/GCP):**\n",
        "- Small deployment: $200-500/month\n",
        "- Medium deployment: $1,000-2,500/month\n",
        "- Large deployment: $5,000+/month\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install EconSync and dependencies\n",
        "%pip install git+https://github.com/deluair/EconSync.git\n",
        "\n",
        "# Install additional requirements for Colab\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install transformers[torch] peft datasets accelerate\n",
        "%pip install chromadb sentence-transformers\n",
        "%pip install pandas numpy matplotlib plotly\n",
        "%pip install statsmodels scipy scikit-learn\n",
        "%pip install rich tqdm loguru\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check available resources\n",
        "import torch\n",
        "import psutil\n",
        "import sys\n",
        "\n",
        "print(f\"üñ•Ô∏è  CPU cores: {psutil.cpu_count()}\")\n",
        "print(f\"üíæ RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
        "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üéÆ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU available - using CPU mode\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üí∞ Detailed Cost Analysis\n",
        "\n",
        "### Deployment Cost Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Cost Analysis for EconSync Deployments\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Deployment cost scenarios\n",
        "cost_scenarios = {\n",
        "    'Platform': [\n",
        "        'Google Colab Free',\n",
        "        'Google Colab Pro', \n",
        "        'Google Colab Pro+',\n",
        "        'AWS EC2 (t3.medium)',\n",
        "        'AWS EC2 (g4dn.xlarge)',\n",
        "        'AWS EC2 (p3.2xlarge)',\n",
        "        'Azure ML (Standard_D4s_v3)',\n",
        "        'Azure ML (Standard_NC6)',\n",
        "        'GCP Vertex AI (n1-standard-4)',\n",
        "        'Local Workstation'\n",
        "    ],\n",
        "    'Monthly Cost ($)': [0, 9.99, 49.99, 67, 526, 3060, 140, 900, 146, 800],\n",
        "    'GPU': ['T4 (limited)', 'T4/P100', 'V100/TPU', 'None', 'T4', 'V100', 'None', 'K80', 'T4', 'RTX 4090'],\n",
        "    'RAM (GB)': [12.7, 12.7, 25.5, 4, 16, 61, 16, 56, 15, 32],\n",
        "    'Storage (GB)': [25, 25, 166, 30, 225, 32, 32, 340, 100, 1000],\n",
        "    'Best For': [\n",
        "        'Development/Testing',\n",
        "        'Small Research',\n",
        "        'Medium Research', \n",
        "        'Basic Production',\n",
        "        'GPU Production',\n",
        "        'Heavy ML Training',\n",
        "        'Enterprise Basic',\n",
        "        'Enterprise GPU',\n",
        "        'ML Pipeline',\n",
        "        'Development'\n",
        "    ]\n",
        "}\n",
        "\n",
        "cost_df = pd.DataFrame(cost_scenarios)\n",
        "print(\"üí∞ EconSync Deployment Cost Analysis:\\n\")\n",
        "print(cost_df.to_string(index=False))\n",
        "\n",
        "# Additional operational costs\n",
        "print(\"\\nüìä Additional Monthly Costs:\")\n",
        "additional_costs = {\n",
        "    'Service': ['OpenAI API', 'Anthropic Claude', 'FRED API', 'Financial Data', 'Vector DB', 'Monitoring'],\n",
        "    'Cost Range': ['$20-200', '$15-150', 'Free', '$100-1000', '$10-100', '$25-100'],\n",
        "    'Usage': ['LLM calls', 'LLM calls', 'Econ data', 'Market data', 'Storage', 'Ops']\n",
        "}\n",
        "additional_df = pd.DataFrame(additional_costs)\n",
        "print(additional_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Generate Synthetic Economic Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate lightweight synthetic datasets optimized for Colab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "def generate_macro_data(days=365):\n",
        "    \"\"\"Generate synthetic macroeconomic indicators\"\"\"\n",
        "    dates = pd.date_range(start='2023-01-01', periods=days, freq='D')\n",
        "    \n",
        "    # Economic relationships and business cycle\n",
        "    t = np.arange(days)\n",
        "    business_cycle = 0.02 * np.sin(2 * np.pi * t / 365) + 0.01 * np.sin(2 * np.pi * t / (365*5))\n",
        "    trend = np.linspace(0, 0.005, days)\n",
        "    noise = np.random.normal(0, 0.003, days)\n",
        "    \n",
        "    data = {\n",
        "        'date': dates,\n",
        "        'gdp_growth': 2.5 + trend + business_cycle + noise,\n",
        "        'inflation': 3.2 + 0.5 * np.sin(2 * np.pi * t / 365) + 0.3 * business_cycle + noise,\n",
        "        'unemployment': 5.5 - 0.5 * business_cycle + noise,\n",
        "        'interest_rate': 4.0 + 0.8 * business_cycle + trend + noise,\n",
        "        'stock_index': 3500 * np.exp(np.cumsum(0.0002 + business_cycle/50 + noise/10)),\n",
        "        'dollar_index': 100 + 5 * np.sin(2 * np.pi * t / 180) + np.cumsum(noise/2)\n",
        "    }\n",
        "    \n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def generate_trade_data(countries=5, months=12):\n",
        "    \"\"\"Generate synthetic trade data\"\"\"\n",
        "    countries_list = ['USA', 'CHN', 'DEU', 'JPN', 'GBR'][:countries]\n",
        "    \n",
        "    trade_data = []\n",
        "    for month in range(1, months + 1):\n",
        "        date = datetime(2023, month, 1)\n",
        "        for exp_country in countries_list:\n",
        "            for imp_country in countries_list:\n",
        "                if exp_country != imp_country:\n",
        "                    # Realistic trade values with gravity model\n",
        "                    base_trade = np.random.lognormal(8, 1.5)\n",
        "                    seasonal = 1 + 0.1 * np.sin(2 * np.pi * month / 12)\n",
        "                    \n",
        "                    trade_data.append({\n",
        "                        'date': date,\n",
        "                        'exporter': exp_country,\n",
        "                        'importer': imp_country,\n",
        "                        'trade_value_million_usd': base_trade * seasonal,\n",
        "                        'tariff_rate': np.random.uniform(0.01, 0.25),\n",
        "                        'product_category': np.random.choice(['Manufacturing', 'Agriculture', 'Services', 'Energy'])\n",
        "                    })\n",
        "    \n",
        "    return pd.DataFrame(trade_data)\n",
        "\n",
        "# Generate the datasets\n",
        "print(\"üîÑ Generating synthetic economic datasets...\")\n",
        "\n",
        "# Generate data (smaller size for Colab)\n",
        "macro_data = generate_macro_data(365)  # 1 year daily data\n",
        "trade_data = generate_trade_data(5, 12)  # 5 countries, 12 months\n",
        "\n",
        "print(f\"‚úÖ Generated {len(macro_data)} macro observations\")\n",
        "print(f\"‚úÖ Generated {len(trade_data)} trade observations\")\n",
        "\n",
        "# Quick statistics\n",
        "print(\"\\nüìà Macro Data Summary:\")\n",
        "print(macro_data[['gdp_growth', 'inflation', 'unemployment', 'interest_rate']].describe().round(2))\n",
        "\n",
        "print(\"\\nüåç Trade Data Summary:\")\n",
        "trade_summary = trade_data.groupby(['exporter', 'importer'])['trade_value_million_usd'].sum().reset_index()\n",
        "print(f\"Total trade relationships: {len(trade_summary)}\")\n",
        "print(f\"Average trade value: ${trade_summary['trade_value_million_usd'].mean():.0f}M\")\n",
        "\n",
        "# Visualize the data\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('üè¢ EconSync: Synthetic Economic Data Overview', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Macro indicators\n",
        "axes[0,0].plot(macro_data['date'], macro_data['gdp_growth'], color='green', linewidth=2)\n",
        "axes[0,0].set_title('üìä GDP Growth Rate (%)', fontweight='bold')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0,1].plot(macro_data['date'], macro_data['inflation'], color='red', linewidth=2)\n",
        "axes[0,1].set_title('üìà Inflation Rate (%)', fontweight='bold')\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0,2].plot(macro_data['date'], macro_data['unemployment'], color='orange', linewidth=2)\n",
        "axes[0,2].set_title('üë• Unemployment Rate (%)', fontweight='bold')\n",
        "axes[0,2].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1,0].plot(macro_data['date'], macro_data['stock_index'], color='blue', linewidth=2)\n",
        "axes[1,0].set_title('üìà Stock Market Index', fontweight='bold')\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Trade analysis\n",
        "country_exports = trade_data.groupby('exporter')['trade_value_million_usd'].sum()\n",
        "country_exports.plot(kind='bar', ax=axes[1,1], color='skyblue')\n",
        "axes[1,1].set_title('üåç Total Exports by Country', fontweight='bold')\n",
        "axes[1,1].tick_params(axis='x', rotation=45)\n",
        "axes[1,1].set_ylabel('Export Value ($M)')\n",
        "\n",
        "# Correlation heatmap\n",
        "corr_data = macro_data[['gdp_growth', 'inflation', 'unemployment', 'interest_rate']].corr()\n",
        "sns.heatmap(corr_data, annot=True, cmap='coolwarm', center=0, ax=axes[1,2])\n",
        "axes[1,2].set_title('üîó Economic Correlations', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Synthetic data generation and visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ü§ñ EconSync Agent Demo (Simplified for Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simplified EconSync Agent Demo for Colab\n",
        "# This demonstrates core functionality without full model loading\n",
        "\n",
        "class MockEconSyncAgent:\n",
        "    \"\"\"Simplified agent for Colab demonstration\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.loaded_datasets = {}\n",
        "        self.adapters = ['macroeconomic_forecasting', 'trade_economics', 'financial_markets']\n",
        "        print(\"ü§ñ Mock EconSync Agent initialized\")\n",
        "    \n",
        "    def load_data(self, dataset_name):\n",
        "        if dataset_name == \"macroeconomic_indicators\":\n",
        "            self.loaded_datasets[dataset_name] = macro_data\n",
        "            print(f\"‚úÖ Loaded {dataset_name}: {len(macro_data)} observations\")\n",
        "        elif dataset_name == \"international_trade\":\n",
        "            self.loaded_datasets[dataset_name] = trade_data\n",
        "            print(f\"‚úÖ Loaded {dataset_name}: {len(trade_data)} observations\")\n",
        "    \n",
        "    def analyze(self, query, data_sources=None, use_adapters=None):\n",
        "        print(f\"üîç Analyzing: {query}\")\n",
        "        print(f\"üìä Using adapters: {use_adapters or 'auto-selected'}\")\n",
        "        \n",
        "        # Mock analysis based on available data\n",
        "        if \"inflation\" in query.lower():\n",
        "            current_inflation = macro_data['inflation'].iloc[-1]\n",
        "            avg_inflation = macro_data['inflation'].mean()\n",
        "            trend = \"increasing\" if current_inflation > avg_inflation else \"decreasing\"\n",
        "            \n",
        "            return {\n",
        "                'query': query,\n",
        "                'analysis': f\"Current inflation rate: {current_inflation:.2f}%. Average: {avg_inflation:.2f}%. Trend: {trend}.\",\n",
        "                'confidence': 0.85,\n",
        "                'data_points': len(macro_data),\n",
        "                'methodology': 'Time series analysis with economic correlations'\n",
        "            }\n",
        "        \n",
        "        elif \"trade\" in query.lower():\n",
        "            total_trade = trade_data['trade_value_million_usd'].sum()\n",
        "            top_exporter = trade_data.groupby('exporter')['trade_value_million_usd'].sum().idxmax()\n",
        "            \n",
        "            return {\n",
        "                'query': query,\n",
        "                'analysis': f\"Total trade volume: ${total_trade:.0f}M. Top exporter: {top_exporter}. Trade shows seasonal patterns.\",\n",
        "                'confidence': 0.78,\n",
        "                'data_points': len(trade_data),\n",
        "                'methodology': 'Gravity model analysis with bilateral trade flows'\n",
        "            }\n",
        "        \n",
        "        return {\n",
        "            'query': query,\n",
        "            'analysis': 'Mock analysis: Economic indicators show typical business cycle patterns with interconnected relationships.',\n",
        "            'confidence': 0.75,\n",
        "            'methodology': 'Integrated LoRA-RAG-ReAct framework'\n",
        "        }\n",
        "    \n",
        "    def forecast(self, variable, horizon=30, method=\"arima\"):\n",
        "        print(f\"üîÆ Forecasting {variable} for {horizon} periods using {method}\")\n",
        "        \n",
        "        if variable.lower() == \"inflation\":\n",
        "            current_value = macro_data['inflation'].iloc[-1]\n",
        "            # Simple trend forecast\n",
        "            recent_trend = macro_data['inflation'].tail(30).diff().mean()\n",
        "            forecast_value = current_value + (recent_trend * horizon)\n",
        "            \n",
        "            return {\n",
        "                'variable': variable,\n",
        "                'horizon': horizon,\n",
        "                'method': method,\n",
        "                'forecast': forecast_value,\n",
        "                'confidence_interval': [forecast_value - 0.5, forecast_value + 0.5],\n",
        "                'confidence': 0.72\n",
        "            }\n",
        "        \n",
        "        return {\n",
        "            'variable': variable,\n",
        "            'forecast': 'Mock forecast available',\n",
        "            'confidence': 0.70\n",
        "        }\n",
        "\n",
        "# Initialize the mock agent\n",
        "agent = MockEconSyncAgent()\n",
        "\n",
        "# Load our synthetic datasets\n",
        "agent.load_data(\"macroeconomic_indicators\")\n",
        "agent.load_data(\"international_trade\")\n",
        "\n",
        "print(\"\\nüéØ Agent ready for analysis!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üìà Economic Analysis Demonstrations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 1: Macroeconomic Analysis\n",
        "print(\"üèõÔ∏è DEMO 1: Macroeconomic Trend Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Analyze inflation trends\n",
        "result1 = agent.analyze(\n",
        "    \"What are the current inflation trends and their relationship with unemployment?\",\n",
        "    data_sources=[\"macroeconomic_indicators\"],\n",
        "    use_adapters=[\"macroeconomic_forecasting\"]\n",
        ")\n",
        "\n",
        "print(f\"üìä Query: {result1['query']}\")\n",
        "print(f\"üîç Analysis: {result1['analysis']}\")\n",
        "print(f\"üéØ Confidence: {result1['confidence']*100:.1f}%\")\n",
        "print(f\"üìà Data Points: {result1['data_points']}\")\n",
        "print(f\"üî¨ Methodology: {result1['methodology']}\")\n",
        "\n",
        "# Phillips Curve Analysis\n",
        "correlation = macro_data[['inflation', 'unemployment']].corr().iloc[0,1]\n",
        "print(f\"\\nüìä Phillips Curve Correlation: {correlation:.3f}\")\n",
        "\n",
        "# Visualize the relationship\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Time series\n",
        "ax1.plot(macro_data['date'], macro_data['inflation'], label='Inflation', color='red', alpha=0.8)\n",
        "ax1_twin = ax1.twinx()\n",
        "ax1_twin.plot(macro_data['date'], macro_data['unemployment'], label='Unemployment', color='blue', alpha=0.8)\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Inflation Rate (%)', color='red')\n",
        "ax1_twin.set_ylabel('Unemployment Rate (%)', color='blue')\n",
        "ax1.set_title('üìà Inflation vs Unemployment Over Time')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Scatter plot (Phillips Curve)\n",
        "ax2.scatter(macro_data['unemployment'], macro_data['inflation'], alpha=0.6, color='purple')\n",
        "z = np.polyfit(macro_data['unemployment'], macro_data['inflation'], 1)\n",
        "p = np.poly1d(z)\n",
        "ax2.plot(macro_data['unemployment'], p(macro_data['unemployment']), \"--\", color='red', linewidth=2)\n",
        "ax2.set_xlabel('Unemployment Rate (%)')\n",
        "ax2.set_ylabel('Inflation Rate (%)')\n",
        "ax2.set_title('üíº Phillips Curve Relationship')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Macroeconomic analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 2: Economic Forecasting\n",
        "print(\"\\nüîÆ DEMO 2: Economic Forecasting\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Generate inflation forecast\n",
        "forecast_result = agent.forecast(\n",
        "    variable=\"inflation\",\n",
        "    horizon=30,\n",
        "    method=\"arima\"\n",
        ")\n",
        "\n",
        "print(f\"üìä Variable: {forecast_result['variable']}\")\n",
        "print(f\"üîÆ Forecast Value: {forecast_result['forecast']:.2f}%\")\n",
        "print(f\"üìÖ Horizon: {forecast_result['horizon']} days\")\n",
        "print(f\"üéØ Confidence: {forecast_result['confidence']*100:.1f}%\")\n",
        "print(f\"üìà Confidence Interval: [{forecast_result['confidence_interval'][0]:.2f}%, {forecast_result['confidence_interval'][1]:.2f}%]\")\n",
        "\n",
        "# Create forecast visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Historical data\n",
        "plt.plot(macro_data['date'], macro_data['inflation'], label='Historical Inflation', color='blue', linewidth=2)\n",
        "\n",
        "# Simple moving average\n",
        "window = 30\n",
        "moving_avg = macro_data['inflation'].rolling(window=window).mean()\n",
        "plt.plot(macro_data['date'], moving_avg, label=f'{window}-day Moving Average', color='orange', linewidth=2)\n",
        "\n",
        "# Forecast point\n",
        "last_date = macro_data['date'].iloc[-1]\n",
        "forecast_date = last_date + timedelta(days=30)\n",
        "plt.axvline(x=last_date, color='red', linestyle='--', alpha=0.7, label='Forecast Start')\n",
        "plt.scatter([forecast_date], [forecast_result['forecast']], color='red', s=100, zorder=5, label='30-day Forecast')\n",
        "\n",
        "# Confidence interval\n",
        "plt.fill_between([forecast_date, forecast_date], \n",
        "                [forecast_result['confidence_interval'][0]], \n",
        "                [forecast_result['confidence_interval'][1]], \n",
        "                alpha=0.3, color='red', label='Confidence Interval')\n",
        "\n",
        "plt.title('üîÆ Inflation Rate: Historical Data and 30-Day Forecast', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Inflation Rate (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Forecasting analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo 3: International Trade Analysis\n",
        "print(\"\\nüåç DEMO 3: International Trade Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Analyze trade patterns\n",
        "trade_result = agent.analyze(\n",
        "    \"Analyze trade patterns and identify the major trading relationships\",\n",
        "    data_sources=[\"international_trade\"],\n",
        "    use_adapters=[\"trade_economics\"]\n",
        ")\n",
        "\n",
        "print(f\"üìä Query: {trade_result['query']}\")\n",
        "print(f\"üîç Analysis: {trade_result['analysis']}\")\n",
        "print(f\"üéØ Confidence: {trade_result['confidence']*100:.1f}%\")\n",
        "print(f\"üìà Data Points: {trade_result['data_points']}\")\n",
        "print(f\"üî¨ Methodology: {trade_result['methodology']}\")\n",
        "\n",
        "# Trade network analysis\n",
        "print(\"\\nüìä Trade Network Analysis:\")\n",
        "\n",
        "# Top trading pairs\n",
        "top_pairs = trade_data.groupby(['exporter', 'importer'])['trade_value_million_usd'].sum().reset_index()\n",
        "top_pairs = top_pairs.nlargest(10, 'trade_value_million_usd')\n",
        "\n",
        "print(\"\\nüèÜ Top 10 Trading Relationships:\")\n",
        "for i, row in top_pairs.iterrows():\n",
        "    print(f\"  {i+1:2d}. {row['exporter']} ‚Üí {row['importer']}: ${row['trade_value_million_usd']:,.0f}M\")\n",
        "\n",
        "# Country analysis\n",
        "country_exports = trade_data.groupby('exporter')['trade_value_million_usd'].sum().sort_values(ascending=False)\n",
        "country_imports = trade_data.groupby('importer')['trade_value_million_usd'].sum().sort_values(ascending=False)\n",
        "\n",
        "print(f\"\\nüìà Export Leaders: {', '.join(country_exports.head(3).index)}\")\n",
        "print(f\"üìâ Import Leaders: {', '.join(country_imports.head(3).index)}\")\n",
        "\n",
        "# Trade balance\n",
        "trade_balance = country_exports - country_imports\n",
        "print(f\"üìä Trade Surplus: {trade_balance[trade_balance > 0].index.tolist()}\")\n",
        "print(f\"üìä Trade Deficit: {trade_balance[trade_balance < 0].index.tolist()}\")\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('üåê International Trade Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Exports by country\n",
        "country_exports.plot(kind='bar', ax=axes[0,0], color='lightgreen')\n",
        "axes[0,0].set_title('üì§ Total Exports by Country')\n",
        "axes[0,0].set_ylabel('Export Value ($M)')\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Imports by country\n",
        "country_imports.plot(kind='bar', ax=axes[0,1], color='lightcoral')\n",
        "axes[0,1].set_title('üì• Total Imports by Country')\n",
        "axes[0,1].set_ylabel('Import Value ($M)')\n",
        "axes[0,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Trade balance\n",
        "trade_balance.plot(kind='bar', ax=axes[1,0], color=['red' if x < 0 else 'green' for x in trade_balance])\n",
        "axes[1,0].set_title('‚öñÔ∏è Trade Balance by Country')\n",
        "axes[1,0].set_ylabel('Trade Balance ($M)')\n",
        "axes[1,0].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Tariff analysis\n",
        "avg_tariffs = trade_data.groupby(['exporter', 'importer'])['tariff_rate'].mean().reset_index()\n",
        "tariff_pivot = avg_tariffs.pivot(index='exporter', columns='importer', values='tariff_rate')\n",
        "im = axes[1,1].imshow(tariff_pivot.values, cmap='Reds', aspect='auto')\n",
        "axes[1,1].set_title('üöß Average Tariff Rates Matrix')\n",
        "axes[1,1].set_xticks(range(len(tariff_pivot.columns)))\n",
        "axes[1,1].set_yticks(range(len(tariff_pivot.index)))\n",
        "axes[1,1].set_xticklabels(tariff_pivot.columns, rotation=45)\n",
        "axes[1,1].set_yticklabels(tariff_pivot.index)\n",
        "plt.colorbar(im, ax=axes[1,1], label='Tariff Rate')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Trade analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Performance Benchmarks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance benchmarking for EconSync components\n",
        "import time\n",
        "from typing import Dict\n",
        "\n",
        "def benchmark_data_processing():\n",
        "    \"\"\"Benchmark data processing performance\"\"\"\n",
        "    print(\"‚è±Ô∏è Benchmarking Data Processing Performance...\")\n",
        "    \n",
        "    # Test dataset sizes\n",
        "    sizes = [100, 500, 1000, 5000]\n",
        "    results = []\n",
        "    \n",
        "    for size in sizes:\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Generate test data\n",
        "        test_macro = generate_macro_data(size)\n",
        "        test_trade = generate_trade_data(5, size//30 if size >= 30 else 1)\n",
        "        \n",
        "        # Basic analysis\n",
        "        correlations = test_macro[['gdp_growth', 'inflation', 'unemployment']].corr()\n",
        "        trade_summary = test_trade.groupby('exporter')['trade_value_million_usd'].sum()\n",
        "        \n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        \n",
        "        results.append({\n",
        "            'data_size': size,\n",
        "            'processing_time': processing_time,\n",
        "            'throughput': size / processing_time\n",
        "        })\n",
        "        \n",
        "        print(f\"  üìä {size:4d} samples: {processing_time:.3f}s ({size/processing_time:.0f} samples/sec)\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "def benchmark_analysis_speed():\n",
        "    \"\"\"Benchmark analysis operations\"\"\"\n",
        "    print(\"\\nüî¨ Benchmarking Analysis Operations...\")\n",
        "    \n",
        "    queries = [\n",
        "        \"Analyze inflation trends\",\n",
        "        \"Examine trade patterns between countries\", \n",
        "        \"Forecast unemployment rates\",\n",
        "        \"Study correlation between GDP and stock market\"\n",
        "    ]\n",
        "    \n",
        "    analysis_times = []\n",
        "    \n",
        "    for query in queries:\n",
        "        start_time = time.time()\n",
        "        result = agent.analyze(query)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        analysis_time = end_time - start_time\n",
        "        analysis_times.append(analysis_time)\n",
        "        \n",
        "        print(f\"  üîç '{query[:30]}...': {analysis_time:.3f}s\")\n",
        "    \n",
        "    avg_time = sum(analysis_times) / len(analysis_times)\n",
        "    print(f\"  üìä Average analysis time: {avg_time:.3f}s\")\n",
        "    \n",
        "    return analysis_times\n",
        "\n",
        "# System resource monitoring\n",
        "def check_system_resources():\n",
        "    \"\"\"Check current system resource usage\"\"\"\n",
        "    print(\"\\nüíª System Resource Usage:\")\n",
        "    \n",
        "    # Memory usage\n",
        "    memory = psutil.virtual_memory()\n",
        "    print(f\"  üíæ Memory: {memory.percent:.1f}% used ({memory.used/1024**3:.1f}GB / {memory.total/1024**3:.1f}GB)\")\n",
        "    \n",
        "    # CPU usage\n",
        "    cpu_percent = psutil.cpu_percent(interval=1)\n",
        "    print(f\"  üñ•Ô∏è  CPU: {cpu_percent:.1f}% usage\")\n",
        "    \n",
        "    # GPU usage (if available)\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_used = torch.cuda.memory_allocated(0) / 1024**3\n",
        "        gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        gpu_percent = (gpu_memory_used / gpu_memory_total) * 100\n",
        "        print(f\"  üéÆ GPU Memory: {gpu_percent:.1f}% used ({gpu_memory_used:.1f}GB / {gpu_memory_total:.1f}GB)\")\n",
        "    \n",
        "    # Data size estimates\n",
        "    macro_size = macro_data.memory_usage(deep=True).sum() / 1024**2\n",
        "    trade_size = trade_data.memory_usage(deep=True).sum() / 1024**2\n",
        "    print(f\"  üìä Data Usage: Macro={macro_size:.1f}MB, Trade={trade_size:.1f}MB\")\n",
        "\n",
        "# Run benchmarks\n",
        "print(\"üèÉ‚Äç‚ôÇÔ∏è Running EconSync Performance Benchmarks\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Data processing benchmark\n",
        "data_results = benchmark_data_processing()\n",
        "\n",
        "# Analysis speed benchmark  \n",
        "analysis_results = benchmark_analysis_speed()\n",
        "\n",
        "# Resource monitoring\n",
        "check_system_resources()\n",
        "\n",
        "# Performance summary\n",
        "print(f\"\\nüìà Performance Summary:\")\n",
        "print(f\"  üöÄ Best Throughput: {max(r['throughput'] for r in data_results):.0f} samples/sec\")\n",
        "print(f\"  ‚ö° Fastest Analysis: {min(analysis_results):.3f}s\")\n",
        "print(f\"  üìä Average Analysis: {sum(analysis_results)/len(analysis_results):.3f}s\")\n",
        "\n",
        "# Visualize performance\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Throughput vs data size\n",
        "sizes = [r['data_size'] for r in data_results]\n",
        "throughputs = [r['throughput'] for r in data_results]\n",
        "ax1.plot(sizes, throughputs, 'bo-', linewidth=2, markersize=8)\n",
        "ax1.set_xlabel('Data Size (samples)')\n",
        "ax1.set_ylabel('Throughput (samples/sec)')\n",
        "ax1.set_title('üìà Data Processing Throughput')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Analysis times\n",
        "query_names = ['Inflation', 'Trade', 'Unemployment', 'GDP-Stock']\n",
        "ax2.bar(query_names, analysis_results, color=['blue', 'green', 'orange', 'red'], alpha=0.7)\n",
        "ax2.set_ylabel('Analysis Time (seconds)')\n",
        "ax2.set_title('‚ö° Analysis Speed by Query Type')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Performance benchmarking complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ Conclusions and Next Steps\n",
        "\n",
        "### ‚úÖ What We've Demonstrated\n",
        "1. **üí∞ Cost-Effective Development**: EconSync runs efficiently in Google Colab (Free: $0, Pro: $9.99/month)\n",
        "2. **üìä Realistic Data Generation**: Created synthetic economic datasets with proper relationships\n",
        "3. **üîç Multi-Domain Analysis**: Demonstrated macro, trade, and forecasting capabilities  \n",
        "4. **‚ö° Performance Benchmarks**: Measured throughput and resource efficiency\n",
        "5. **üåê Scalable Architecture**: From development to production deployment\n",
        "\n",
        "### üîç Key Insights\n",
        "- **Development Costs**: $0-50/month using Google Colab\n",
        "- **Production Costs**: $200-3,000/month depending on scale and requirements\n",
        "- **Performance**: 1000+ samples/second data processing capability\n",
        "- **Memory Efficiency**: Optimized for resource-constrained environments\n",
        "- **Modular Design**: Easy to extend with new adapters and capabilities\n",
        "\n",
        "### üìà Cost-Benefit Analysis\n",
        "| Deployment Type | Monthly Cost | Best For | ROI Timeline |\n",
        "|----------------|--------------|----------|--------------|\n",
        "| Colab Free | $0 | Learning/Testing | Immediate |\n",
        "| Colab Pro | $10 | Small Research | 1 month |\n",
        "| AWS Small | $200-500 | Production Pilot | 3-6 months |\n",
        "| Enterprise | $1000+ | Full Production | 6-12 months |\n",
        "\n",
        "### üöÄ Recommended Next Steps\n",
        "\n",
        "#### üìö **For Researchers:**\n",
        "1. **Expand Datasets**: Add real economic data sources (FRED, World Bank, IMF)\n",
        "2. **Fine-tune Models**: Train domain-specific LoRA adapters on your research area\n",
        "3. **Collaborate**: Share findings and extend the framework\n",
        "\n",
        "#### üè¢ **For Organizations:**\n",
        "1. **Pilot Deployment**: Start with Colab Pro for initial testing\n",
        "2. **Data Integration**: Connect to internal economic databases\n",
        "3. **Custom Adapters**: Develop organization-specific economic models\n",
        "4. **Scale Gradually**: Move to cloud deployment as usage grows\n",
        "\n",
        "#### üî¨ **For Developers:**\n",
        "1. **Contribute**: Add new economic models and analysis methods\n",
        "2. **Optimize**: Improve performance and reduce computational costs\n",
        "3. **Extend**: Build domain-specific extensions (energy, healthcare, etc.)\n",
        "\n",
        "### üìä Production Deployment Roadmap\n",
        "\n",
        "#### **Phase 1: Development (Month 1-2)**\n",
        "- ‚úÖ Use Google Colab Pro ($10/month)\n",
        "- ‚úÖ Generate synthetic datasets\n",
        "- ‚úÖ Test core functionality\n",
        "- ‚úÖ Validate analysis methods\n",
        "\n",
        "#### **Phase 2: Pilot (Month 3-6)**\n",
        "- üîÑ Move to AWS/GCP small instance ($200-500/month)\n",
        "- üîÑ Integrate real economic data sources\n",
        "- üîÑ Train specialized LoRA adapters\n",
        "- üîÑ User testing and feedback\n",
        "\n",
        "#### **Phase 3: Production (Month 6+)**\n",
        "- üîÑ Scale to full cloud deployment ($1000+/month)\n",
        "- üîÑ Enterprise security and compliance\n",
        "- üîÑ Multi-user support and dashboards\n",
        "- üîÑ Continuous model updates\n",
        "\n",
        "### üí° Innovation Opportunities\n",
        "\n",
        "1. **ü§ñ Advanced AI**: Integration with GPT-4, Claude, and specialized economic LLMs\n",
        "2. **üì± Mobile Apps**: Real-time economic analysis on mobile devices\n",
        "3. **üåê Web Platform**: Browser-based economic research platform\n",
        "4. **üîó API Services**: RESTful APIs for third-party integration\n",
        "5. **üìà Real-time Analytics**: Live market and economic monitoring\n",
        "\n",
        "### üåç Impact Potential\n",
        "\n",
        "- **üéì Academic Research**: Faster hypothesis testing and literature reviews\n",
        "- **üèõÔ∏è Policy Making**: Real-time policy impact assessment\n",
        "- **üíº Business Intelligence**: Market analysis and economic forecasting\n",
        "- **üìä Financial Services**: Risk assessment and investment analysis\n",
        "- **üå± Democratization**: Making advanced economics accessible to all\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Resources and Links\n",
        "\n",
        "- **üîó GitHub Repository**: [https://github.com/deluair/EconSync](https://github.com/deluair/EconSync)\n",
        "- **üìñ Documentation**: Comprehensive setup and usage guides\n",
        "- **üí¨ Community**: Join discussions and contribute to development\n",
        "- **üêõ Issues**: Report bugs and request features\n",
        "- **üìä Examples**: Additional analysis notebooks and tutorials\n",
        "\n",
        "### üéâ **Ready to Get Started?**\n",
        "\n",
        "1. **‚≠ê Star** the repository on GitHub\n",
        "2. **üç¥ Fork** it for your own experiments  \n",
        "3. **üìù Contribute** improvements and extensions\n",
        "4. **üí¨ Share** your economic research findings\n",
        "\n",
        "**EconSync: Empowering the future of economic research with AI** üåçüìäü§ñ\n",
        "\n",
        "---\n",
        "\n",
        "*Thank you for exploring EconSync! Your feedback and contributions help make economic research more accessible and powerful for everyone.*\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
